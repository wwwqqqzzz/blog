---
slug: crawler-diary
title: 真的就是我的爬虫日记
date: 2025-08-09
authors: [wqz]
tags: [爬虫, 日记, 技术]
image: https://cdn.jsdelivr.net/gh/wwwqqqzzz/Image/img/1754694913303-717f72ef231175efd83a354d9bbd49c5.png
description: "五天抓全球媒体邮箱的爬虫实战日记，记录 Playwright、代理池、断点续传等踩坑与收获"
keywords: [爬虫, Playwright, 代理池, 邮箱抓取, 爬虫实战]
collection: 爬虫合集
collection_order: 1
collection_description: 记录爬虫相关项目与心得的文章合集
---

先说结论：项目还在跑，我还在肝，希望交付那天我还能笑得出来。

---

## 事情是这样开始的

老板丢给我一句话：
> “五天之内，把全球报纸/新闻网站/杂志的邮箱爬下来，2000块，周三给我结果。”

行吧，穷鬼如我，接了。

网站有两个：w3newspapers 和 scimagomedia。我挑了后者，队友 gjy 负责前者。心想：排行页面，看着就好搞。

第一次接单能顺利开张，还得谢 gjy 带飞。

第一天甩头就写脚本，动了三小时发现——呃，邮箱在哪？页面里根本没有！

## 被 AI 带沟里

我跑去问 GPT，它一本正经地让我去抓 SJR 的数据。我还真听了，哐哐爬了一晚，第二天对着一堆“期刊影响因子”直接懵了——这玩意儿跟邮箱有啥关系？

鬼知道那一刻我有多想掐死它（虽然它没脖子）。

## 转机：下载按钮

继续扒站的时候瞄到一个不起眼的“Download Excel”。点开，6000 多行域名躺那儿——“就是你了！”

脚本改成：读 Excel → 进站 → 找邮箱。听起来简单，做起来……呵呵。

## 准确率惨不忍睹

第一版只能抓到十几个邮箱。加重试、换 UA、正则满天飞、线程拉满，还是一堆 403。

Cloudflare 像铁门一样挡在那——我敲了半天门，门卫只回我一句 “Access Denied”。

## 搬救兵

再次求助 AI，这次它靠谱点：
1. 用 Playwright 假装真人点点点。
2. 把域名分档：先快跑一遍，失败的再慢慢啃。
3. 加免费代理池。

照做之后，能把 forbes、reuters 的邮箱抓出来，成就感+10086。

## 速度 vs 准确率：永恒之战

线程一多就超时，线程一少又慢得想睡。调来调去，效率上不去，准确率下不来。

最后妥协：
- 快速爬 → 拿 40% 邮箱先。
- 失败清单丢给“慢但狠”的策略。
- 特别重要的站点再手动开浏览器。

## 世界上最贵的脚

昨晚临睡前看进度 85%，我乐呵呵去倒杯水，结果脚勾到插线板……啪，黑屏。

18 小时记录说没就没。

当场石化。教训：断点续传必须有！

## 现在的战况

- 结构整理完，文件都塞进 src / data / logs… 各自位置。
- 日志和进度文件写好了，断电也不怕。
- 准确率大概 60%，还能再救一点。

## 时间表（真·赶鸭子上架）

- **今天**：让脚本跑完，整理失败列表。
- **明天**：对失败站开二次爬 → 清洗去重 → 写交付说明。
- **后天早上**：最后验收，发货，收钱！

## 想说点人话的总结

1. 别盲信 AI，它能给方向，也能坑你。
2. 备份、断点、日志，缺一条就等着哭。
3. 真实项目比教程脏多了，可学到的也多。

写到这儿脚本还在喘，一会儿再去看日志。祝我好运，也祝屏幕前的你少掉坑里。

—— 2025/08/08 深夜，咖啡见底
