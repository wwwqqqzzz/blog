---
cssclasses:
  - ai
  - 教程
  - 基础理论
tags:
  - ai学习
  - 教程
  - AI
  - 机器学习
title: 机器学习基础 - AI的底层逻辑
date: 2026-02-01
authors:
  - wqz
description: 理解机器学习的核心范式,为什么这些P2理论是现代AI的基础
collection: 第零部分：基础理论层
slug: ml-basics
collection_order: 1
---

# 机器学习基础 - AI的底层逻辑

> **💡 写在前面**
> 这一章我们不整那些吓人的数学公式（什么偏导数、矩阵乘法先放一边）。
> 我们的目标是建立**直觉**，搞清楚：**为了让机器学会做一件事，工程师到底做了什么？**

---

## 1. 编程范式的转移：从 1.0 到 2.0

我们要学的不是一种新的编程语言，而是一种**全新的思考方式**。

![alt text](assets/image.png)

### 传统的编程（Software 1.0）

如果你是一个写业务代码的工程师，你每天做的事情大概是这样的：
**你告诉计算机每一条具体的规则。**

- **场景**：判断一张照片里是不是猫。
- **做法**：你得写 `if (有耳朵) and (有胡须) and (毛茸茸)...`
- **问题**：这根本写不完！老虎也有耳朵胡须，玩具猫怎么算？规则稍微变一点，代码就得重写。

$$ 规则 + 数据 = 答案 $$

### 机器学习（Software 2.0）

现在我们换个思路。既然规则太复杂写不出来，那能不能**让机器自己把规则找出来**？

我们不写规则了，我们给机器看**一万张猫的照片**和**一万张不是猫的照片**，然后跟它说："你自己找规律，反正左边这些必须叫'猫'，右边这些不行。"

机器经过一通计算，最后它总结出了一套超级复杂的数学公式（可能有一亿个参数），这套公式能完美区分猫和狗。这套公式，就是我们炼出来的**模型**。

$$ 答案 + 数据 = 规则 $$

**这就是机器学习的核心：用数据换取规则。**

---

## 2. 三大核心流派：机器是怎么"学"的？

其实和人类学习的过程一模一样。

![alt text](assets/image-1.png)

### 2.1 监督学习 (Supervised Learning)

:::tip 类比：学生刷题（带标准答案）
这是最主流、应用最广的方法。

- **老师（工程师）**：给你这本《五年高考三年模拟》，每道题后面都有答案。
- **学生（模型）**：做题 -> 对答案 -> 发现错了 -> 修正脑子里的思路。
- **应用**：
  - **分类**：这封邮件是垃圾邮件吗？（是/否）
  - **回归**：这房子明年只要多少钱？（预测具体数值）
    :::

### 2.2 无监督学习 (Unsupervised Learning)

:::tip 类比：把一堆乐高积木分类（没说明书）
老师这回不给答案了，就把一堆数据扔给你："你自己看看有什么规律。"

- **学生（模型）**：哎，这几个红色的块块挺像的，堆一起；那些长条的形状差不多，堆一起。
- **应用**：
  - **聚类**：把用户分成"高价值用户"、"薅羊毛用户"（虽然我一开始不知道他们叫什么，但行为模式很像）。
  - **关联规则**：买了啤酒的人通常也会买尿布。
    :::

### 2.3 强化学习 (Reinforcement Learning)

:::tip 类比：训练小狗（给骨头或打屁股）
没有现成的数据集，而是通过**互动**来学习。**本质是：没有标准答案，只有长期回报。**

- **环境**：给模型一个场景（比如玩《马里奥》游戏）。
- **反馈**：
  - 往右走吃金币 -> **奖励 +1**（做得好！）
  - 掉坑里摔死了 -> **惩罚 -10**（别这么干！）
- **目标**：模型疯狂试错，最后学会了怎么拿最高分。
- **应用**：AlphaGo 下围棋、机器人走路、DeepSeek-R1 的推理能力训练。
  :::

---

## 3. 工程师黑话指南（核心词汇）

以后看论文、看文档，你会反复看到这几个词，先把它们映射到人话。

| 黑话 (Term)                | 人话映射             | 例子                                 |
| :------------------------- | :------------------- | :----------------------------------- |
| **Dataset (数据集)**       | 教材库               | 一万张猫的照片                       |
| **Features (特征, X)**     | 题目的已知条件       | 照片的像素、房子的面积、地段         |
| **Labels (标签, y)**       | 标准答案             | "这是一只猫"、"房价500万"            |
| **Model (模型)**           | 那个负责做题的脑子   | 一个巨大的数学函数 $f(x)$            |
| **Parameters (权重/参数)** | 脑子里的神经连接强弱 | 也就是我们最后训练出来的"规则"本身   |
| **Training (训练)**        | 刷题的过程           | 调整参数，让正确率越来越高           |
| **Inference (推理)**       | 考试                 | 训练已经结束，拿新题来由模型输出答案 |
| **Evaluation (评估)**      | **判卷老师**         | **衡量模型在真实场景下是否真的有用** |

---

## 4. 机器"学习"的本质：The Learning Loop

这是本章最重要的部分。所谓的"训练模型"，其实就是在跑一个**死循环**。

![alt text](assets/image-3.png)

想象一个蒙着眼睛的人下山：

1.  **猜 (Predict/Forward Pass)**
    模型拿到一道题，先瞎猜一个答案。
    - _模型：我觉得这是猫！_

2.  **对答案 (Loss Function)**
    用**损失函数 (Loss Function)** 来衡量猜得有多离谱。
    - _裁判：错！这是狗。你的答案离正确答案差了十万八千里（Loss = 1000）。_

3.  **找方向 (Gradient)**
    这就涉及到了传说中的"梯度"。你就把它理解为**坡度**。
    - _模型：那我该往哪个方向改呢？是把参数调大点还是调小点？_

4.  **改错 (Optimizer)**
    用**优化器 (Optimizer)** 修改模型里的参数。
    - _优化器：刚才那个参数调小一点点，下次应该能对。_

**这个循环跑几百万次（Epochs），直到 Loss 几乎变成 0，我们就说：训练好了！**

---

## 5. 拆解核心组件 (Deep Dive)

既然我们知道了学习的循环，那这两个关键角色——**损失函数**和**优化器**——到底是怎么工作的？

### 5.1 损失函数 (Loss Function)：衡量"错误"的尺子

**Loss Function (Cost Function)** 的作用只有一个：**告诉模型，你现在错得有多离谱。**

如果模型猜错了，Loss 就会很高；如果猜对了，Loss 就接近 0。

#### 为什么要专门设计这个？

因为"错"有很多种错法。

> [!TIP]
>
> **举个栗子**：射击比赛 🎯
>
> - **场景 A**：你脱靶了 1 米。
> - **场景 B**：你脱靶了 10 米。
>
> 对于 **MSE (均方误差)** 这种 Loss 来说，场景 B 的惩罚不是场景 A 的 10 倍，而是 **100 倍** ($10^2$)。它非常痛恨大错误，逼着你必须消除那些严重的失误。

#### 常见的 Loss Function：

1.  **MSE (Mean Squared Error)**
    - **用于**：回归问题（预测房价、气温）。
    - **特点**：**严厉的老师**。如果你错一点点，它不怎么管你；但如果你错得太离谱，它会狠狠地惩罚你（平方级放大错误）。
2.  **Cross Entropy (交叉熵)**
    - **用于**：分类问题（是猫还是狗）。
    - **特点**：**概率的裁判**。它不看你偏离了几米，而是看你有多大的**确信度**猜错了。如果你很自信地指着猫说是狗，它的惩罚会爆炸级增长。

Loss 越低，代表模型越强。主要目标就是：**Minimize Loss**。

**注意**：Loss 越低，通常代表模型越强，**但在训练集上 Loss 低不代表在考场上（测试集）也能考好**（这叫过拟合），不过这是后话了，目前我们的主要目标就是：**Minimize Loss**。

### 5.2 优化器 (Optimizer)：下山的指路人

我们知道了自己错在哪（Loss），也知道了错得有多离谱，但**怎么改**才能让 Loss 变小呢？

这就需要**优化器**出手了。最经典的算法叫 **梯度下降 (Gradient Descent)**。

#### ⛰️ 下山的比喻

![alt text](assets/image-4.png)

想象你被蒙着眼睛扔到了一座高山上（高 Loss），你的目标是走到山谷最低点（Loss = 0）。

1.  **梯度 (Gradient)**：
    你用脚探一探周围，发现往左走是上坡，往右走是下坡。这个“坡度”就是梯度。
    - _原则_：**永远沿着坡度最陡的方向往下走。**

2.  **学习率 (Learning Rate)**：
    确定了方向，你要迈多大一步？
    - **步子太大 (High LR)**：可能直接跨过了山谷，跑到了对面的山上（震荡）。
    - **步子太小 (Low LR)**：像蚂蚁搬家一样挪，天黑了还没下山（训练太慢）。
    - _调参_：找到一个完美的步长，是工程师的基本功。

#### 常见的优化器：

- **SGD (随机梯度下降)**：最朴素的下山法。看见坡就下，不管三七二十一。容易走弯路，但最终能下去。
- **Adam (Adaptive Moment Estimation)**：现在的**默认首选**。它很聪明，既看坡度，也看之前的惯性（动量）。
  - _比喻_：像一个带了重力感应滑板的运动员，遇到平地会利用惯性冲过去，遇到陡坡会加速。**它通常学得更快、更好。**

---

## 6. 总结

1.  **机器学习**就是用**数据**反推**规则**。
2.  我们最常用的**监督学习**，本质上就是带答案的刷题。
3.  **训练**的过程，就是不断**猜答案 -> 挨骂（Loss高） -> 改错**的循环。

**下一章预告**：
既然搞懂了机器学习的基本逻辑（找规律），那如果要处理更复杂的问题（比如图像、自然语言），这套逻辑够用吗？为什么我们需要**神经网络**？我们将进入 **《1.2 深度学习原理》**。

---

## **【延伸阅读】**

- _Machine Learning is Fun! (Adam Geitgey)_ - 极其通俗的入门读物
- _Andrej Karpathy's Software 2.0_ - 经典的理念阐述

---

**下一章**: [深度学习原理](/blog/deep-learning-core)
