---
cssclasses:
  - ai
  - 基础理论
tags:
  - ai学习
  - cnn
  - 计算机视觉
  - 深度学习
  - ResNet
title: CNN卷积网络 - 曾经的视觉霸主
date: 2026-02-02
authors:
  - wqz
description: 在 Transformer 统治世界之前，它是 AI 的眼睛。
collection: 第零部分：基础理论层
slug: cnn-bridge
collection_order: 3
---

# CNN卷积网络 - 曾经的视觉霸主

:::info 承上启下
在上一章，我们学习了全连接神经网络。虽然它什么都能算，但在处理图片时有个大问题：**参数爆炸**。
这一章我们来讲讲 **CNN (Convolutional Neural Network)**，它是如何让 AI 第一次看懂世界的。
虽然在今天的大模型时代，CNN 的地位已经被 Transformer 挑战，但它依然是理解“特征提取”最好的老师。
:::

---

## 1. 为什么全连接网络搞不定图片？

所谓**全连接网络 (Fully Connected Network)**，就是我们上一章画的那种最直观的模型：**每一个输入像素，都要跟下一层的每一个神经元连一条线**。

假设你有一张手机拍的照片（1200万像素）。
如果用全连接网络，把每个像素点都当成一个输入：

$$ 1200\text{万像素} \times 3 (\text{RGB通道}) \times 1000 (\text{隐藏层神经元}) \approx 360 \text{亿个参数} $$

这还只是第一层！这还没算显卡内存爆炸的问题。

**更重要的是，这违反了人类看东西的直觉。**

当你找照片里的猫时，你会死盯着左上角那个像素点的 RGB 值看吗？
不会。你是**看特征**：这里有个尖尖的耳朵，那里有个毛茸茸的尾巴。
而且，猫在左上角还是右下角，它都是猫（平移不变性）。

---

## 2. 卷积的直觉：手电筒与滤镜

CNN 的核心发明是 **卷积 (Convolution)**。
别被这个数学名词吓到，其实它就是**带着滤镜的手电筒**。

> ![image-20260203160953223](./assets/image-20260203160953223.png)

1.  **滤镜 (Filter/Kernel)**：这不仅仅是个手电筒，它的镜片是有图案的。
    - 有的滤镜专门找**竖线**。
    - 有的滤镜专门找**圆圈**。
    - 有的滤镜专门找**眼睛形状**。
2.  **滑动扫描 (Sliding)**：拿着这个手电筒，从图片的左上角扫到右下角。
3.  **激活**：如果手电筒照到的地方，跟滤镜上的图案很像，它就会灯亮起（输出高数值）。

这就叫**特征提取**。我们不需要看几千万个像素，只需要知道“哪里有竖线”、“哪里有眼睛”。

---

## 3. 抽象的阶梯：Pooling (池化)

扫完一遍后，图片还是很大。这时候需要 **Pooling (池化)**。
它的逻辑很简单：**缩略图**。

把一张大图缩小一半，细节虽然丢了，但**宏观轮廓**还在。

- Layer 1：看到很多线条（横线、竖线）。
- Layer 2：线条组成了部件（尖尖的形状、圆圆的形状）。
- Layer 3：部件组成了器官（**猫耳朵**、**猫眼睛**、**胡须**）。
- Layer 4：器官组成了整体（**一只完整的猫**）。

这就是深度学习的精髓：**层层抽象**。

> ![image-20260203161118780](./assets/image-20260203161118780.png)

---

## 4. 为什么大模型时代它退位了？

CNN 统治了计算机视觉（CV）整整 10 年（2012 AlexNet - 2020 Vision Transformer）。
但在今天，GPT-4V、Sora、Claude 用的视觉编码器，越来越多地转向了 **Transformer** 架构（ViT）。

为什么？

### 1. 视野限制 (The Receptive Field Issue)

CNN 是**局部**着眼的。
它一次只能看一个 3x3 小窗口。虽然叠很多层后能看全图，但它天生对“全局关系”不敏感。

- CNN：看鼻子是鼻子，看嘴是嘴。
- Transformer：**第一眼就看到了整张脸**（Global Attention）。

:::warning 💡 归纳偏置 (Inductive Bias)

- **CNN** 有很强的**归纳偏置**：它预设了“像素之间是局部相关”的。所以它不需要太多数据就能训练出不错的效果（省数据）。
- **Transformer** 几乎没有归纳偏置：它假设“万物皆可关联”。所以它需要**海量数据**才能把这些关系学出来（费数据，但上限极高）。
  这就是为什么 Vision Transformer (ViT) 直到最近数据量爆炸了才打败 CNN。
  :::

> - ![image-20260203164005401](./assets/image-20260203164005401.png)

### 2. 多模态统一

语言（Text）是序列，图片（Image）在 Transformer 眼里切块后也是序列。
用同一套架构（Transformer）处理所有模态，工程上最优雅，效果也更容易迁移。

---

## 5. 总结

:::note 本章核心

1.  **卷积 (Convolution)**：是为了解决全连接网络参数爆炸的问题，利用了“局部性”和“平移不变性”。
2.  **特征提取**：CNN 是最好的特征提取器，它教会了我们怎么把原始像素变成抽象概念。
3.  **历史地位**：它是深度学习爆发的功臣。虽然在 LLM 时代退居二线，但在端侧设备（手机、摄像头）上，由它驱动的高效视觉应用依然无处不在。
    :::

---

**下一章预告**：
CNN 解决了**空间**上的局部关系，那**时间**上的先后关系（比如读文章、听语音）怎么办？
接下来，有请真正的天选之子出场。

---

**下一章**: [Transformer基础](/blog/transformer-basics)
